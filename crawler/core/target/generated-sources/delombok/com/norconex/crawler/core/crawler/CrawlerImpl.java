// Generated by delombok at Fri Mar 08 16:24:33 MST 2024
/* Copyright 2022-2023 Norconex Inc.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package com.norconex.crawler.core.crawler;

import java.util.function.BiConsumer;
import java.util.function.Consumer;
import java.util.function.Function;
import java.util.function.Supplier;
import org.apache.commons.lang3.mutable.MutableBoolean;
import com.norconex.commons.lang.ClassUtil;
import com.norconex.crawler.core.doc.CrawlDoc;
import com.norconex.crawler.core.doc.CrawlDocRecord;
import com.norconex.crawler.core.doc.CrawlDocRecordFactory;
import com.norconex.crawler.core.fetch.FetchRequest;
import com.norconex.crawler.core.fetch.FetchResponse;
import com.norconex.crawler.core.fetch.Fetcher;
import com.norconex.crawler.core.pipeline.committer.CommitterPipeline;
import com.norconex.crawler.core.pipeline.importer.ImporterPipeline;
import com.norconex.crawler.core.pipeline.queue.QueuePipeline;
import lombok.Builder.Default;
import lombok.NonNull;

/**
 * <p>
 * Inner workings specific to a given crawler implementation. Not
 * for general use, and not meant to be configured <i>directly</i> at runtime.
 * </p>
 */
@SuppressWarnings("javadoc")
public class CrawlerImpl {
    /**
     * Holds objects specific to a given crawler implementation.
     * Useful for keeping objects and state not directly part of
     * Crawler.
     */
    @NonNull
    Supplier<Object> crawlerImplContext;
    /**
     * Provides a required fetcher implementation, responsible for obtaining
     * resources being crawled using one or more different fetcher
     * implementations.
     */
    @NonNull
    Function<Crawler, ? extends Fetcher<? extends FetchRequest, ? extends FetchResponse>> fetcherProvider;
    //TODO Needed since we also have CrawlDocRecord Factory? keep only one?
    /**
     * The exact type of {@link CrawlDocRecord} if your crawler is subclassing
     * it. Defaults to {@link CrawlDocRecord} class.
     */
    @NonNull
    Class<? extends CrawlDocRecord> crawlDocRecordType;
    /**
     * Required pipeline to be executed for each reference that should
     * end-up in the crawler queue.
     */
    @NonNull
    QueuePipeline queuePipeline;
    /**
     * Required pipeline to be executed for each reference read
     * from the crawler queue up to the importing of the corresponding
     * document.
     */
    @NonNull
    ImporterPipeline importerPipeline;
    /**
     * Required pipeline to be executed for each document that has been
     * imported and are ready to be committed for insertion/update or
     * deletion.
     */
    @NonNull
    CommitterPipeline committerPipeline;


    /**
     * Holds contextual objects necessary to initialize a crawler queue.
     */
    public static class QueueInitContext {
        private final Crawler crawler;
        private final boolean resuming;
        private final Consumer<CrawlDocRecord> queuer;

        public void queue(@NonNull String reference) {
            java.util.Objects.requireNonNull(reference, "reference is marked non-null but is null");
            var rec = ClassUtil.newInstance(crawler.getCrawlerImpl().crawlDocRecordType());
            rec.setReference(reference);
            rec.setDepth(0);
            queue(rec);
        }

        public void queue(@NonNull CrawlDocRecord rec) {
            java.util.Objects.requireNonNull(rec, "rec is marked non-null but is null");
            queuer.accept(rec);
        }

        @java.lang.SuppressWarnings("all")
        @lombok.Generated
        public QueueInitContext(final Crawler crawler, final boolean resuming, final Consumer<CrawlDocRecord> queuer) {
            this.crawler = crawler;
            this.resuming = resuming;
            this.queuer = queuer;
        }

        @java.lang.SuppressWarnings("all")
        @lombok.Generated
        public Crawler getCrawler() {
            return this.crawler;
        }

        @java.lang.SuppressWarnings("all")
        @lombok.Generated
        public boolean isResuming() {
            return this.resuming;
        }
    }

    /**
     * Function responsible for initializing a queue, which typically involved
     * inserting the initial references necessary to start crawling.
     * The function's return value indicate if we are done initializing
     * the queue.  Should always be <code>true</code> unless
     * the queue can be initialized asynchronously. In such case,
     * the mutable boolean can be returned right away, but must be set to
     * <code>true</code> when initialization is complete.
     * Defaults to {@link CoreQueueInitializer}.
     */
    Function<QueueInitContext, MutableBoolean> queueInitializer;


    /**
     * Holds contextual objects necessary to create new document records.
     */
    public static class DocRecordFactoryContext {
        private final String reference;
        private final CrawlDocRecord parentDocRecord;
        private final CrawlDocRecord cachedDocRecord;

        @java.lang.SuppressWarnings("all")
        @lombok.Generated
        DocRecordFactoryContext(final String reference, final CrawlDocRecord parentDocRecord, final CrawlDocRecord cachedDocRecord) {
            this.reference = reference;
            this.parentDocRecord = parentDocRecord;
            this.cachedDocRecord = cachedDocRecord;
        }


        @java.lang.SuppressWarnings("all")
        @lombok.Generated
        public static class DocRecordFactoryContextBuilder {
            @java.lang.SuppressWarnings("all")
            @lombok.Generated
            private String reference;
            @java.lang.SuppressWarnings("all")
            @lombok.Generated
            private CrawlDocRecord parentDocRecord;
            @java.lang.SuppressWarnings("all")
            @lombok.Generated
            private CrawlDocRecord cachedDocRecord;

            @java.lang.SuppressWarnings("all")
            @lombok.Generated
            DocRecordFactoryContextBuilder() {
            }

            /**
             * @return {@code this}.
             */
            @java.lang.SuppressWarnings("all")
            @lombok.Generated
            public CrawlerImpl.DocRecordFactoryContext.DocRecordFactoryContextBuilder reference(final String reference) {
                this.reference = reference;
                return this;
            }

            /**
             * @return {@code this}.
             */
            @java.lang.SuppressWarnings("all")
            @lombok.Generated
            public CrawlerImpl.DocRecordFactoryContext.DocRecordFactoryContextBuilder parentDocRecord(final CrawlDocRecord parentDocRecord) {
                this.parentDocRecord = parentDocRecord;
                return this;
            }

            /**
             * @return {@code this}.
             */
            @java.lang.SuppressWarnings("all")
            @lombok.Generated
            public CrawlerImpl.DocRecordFactoryContext.DocRecordFactoryContextBuilder cachedDocRecord(final CrawlDocRecord cachedDocRecord) {
                this.cachedDocRecord = cachedDocRecord;
                return this;
            }

            @java.lang.SuppressWarnings("all")
            @lombok.Generated
            public CrawlerImpl.DocRecordFactoryContext build() {
                return new CrawlerImpl.DocRecordFactoryContext(this.reference, this.parentDocRecord, this.cachedDocRecord);
            }

            @java.lang.Override
            @java.lang.SuppressWarnings("all")
            @lombok.Generated
            public java.lang.String toString() {
                return "CrawlerImpl.DocRecordFactoryContext.DocRecordFactoryContextBuilder(reference=" + this.reference + ", parentDocRecord=" + this.parentDocRecord + ", cachedDocRecord=" + this.cachedDocRecord + ")";
            }
        }

        @java.lang.SuppressWarnings("all")
        @lombok.Generated
        public static CrawlerImpl.DocRecordFactoryContext.DocRecordFactoryContextBuilder builder() {
            return new CrawlerImpl.DocRecordFactoryContext.DocRecordFactoryContextBuilder();
        }

        @java.lang.SuppressWarnings("all")
        @lombok.Generated
        public String reference() {
            return this.reference;
        }

        @java.lang.SuppressWarnings("all")
        @lombok.Generated
        public CrawlDocRecord parentDocRecord() {
            return this.parentDocRecord;
        }

        @java.lang.SuppressWarnings("all")
        @lombok.Generated
        public CrawlDocRecord cachedDocRecord() {
            return this.cachedDocRecord;
        }
    }

    /**
     * Function responsible for creating new document records
     * specific to this crawler implementation. The default factory
     * creates instances of {@link CrawlDocRecord} initialized with
     * a possible parent document record.
     */
    @NonNull
    CrawlDocRecordFactory docRecordFactory;
    /**
     * Gives crawler implementations a chance to prepare before execution
     * starts. Invoked right after the
     * {@link CrawlerEvent#CRAWLER_RUN_BEGIN} event is fired.
     * This method is different than the {@link #initCrawler()} method,
     * which is invoked for any type of actions where as this one is only
     * invoked before an effective request for crawling.
     */
    BiConsumer<Crawler, Boolean> beforeCrawlerExecution;
    /**
     * Gives crawler implementations a chance to do something right after
     * the crawler is done processing its last reference, before all resources
     * are shut down.
     * Invoked right after {@link CrawlerEvent#CRAWLER_STOP_END} or
     * {@link CrawlerEvent#CRAWLER_RUN_END} (depending which of the two is
     * triggered).
     */
    Consumer<Crawler> afterCrawlerExecution;
    //TODO are those used? Should they be?
    // Add those that are missing to ReferencesProcessor
    BiConsumer<Crawler, CrawlDoc> beforeDocumentProcessing;
    BiConsumer<Crawler, CrawlDoc> afterDocumentProcessing;
    // need those, or we can replace beforeDocumentFinalizing
    // (the only one used) with after processing?
    BiConsumer<Crawler, CrawlDoc> beforeDocumentFinalizing;
    BiConsumer<Crawler, CrawlDoc> afterDocumentFinalizing;

    @java.lang.SuppressWarnings("all")
    @lombok.Generated
    private static Supplier<Object> $default$crawlerImplContext() {
        return CrawlerImplContext::new;
    }

    @java.lang.SuppressWarnings("all")
    @lombok.Generated
    private static Class<? extends CrawlDocRecord> $default$crawlDocRecordType() {
        return CrawlDocRecord.class;
    }

    @java.lang.SuppressWarnings("all")
    @lombok.Generated
    private static Function<QueueInitContext, MutableBoolean> $default$queueInitializer() {
        return new CoreQueueInitializer();
    }

    @java.lang.SuppressWarnings("all")
    @lombok.Generated
    private static CrawlDocRecordFactory $default$docRecordFactory() {
        return ctx -> new CrawlDocRecord(ctx.parentDocRecord);
    }

    @java.lang.SuppressWarnings("all")
    @lombok.Generated
    CrawlerImpl(@NonNull final Supplier<Object> crawlerImplContext, @NonNull final Function<Crawler, ? extends Fetcher<? extends FetchRequest, ? extends FetchResponse>> fetcherProvider, @NonNull final Class<? extends CrawlDocRecord> crawlDocRecordType, @NonNull final QueuePipeline queuePipeline, @NonNull final ImporterPipeline importerPipeline, @NonNull final CommitterPipeline committerPipeline, final Function<QueueInitContext, MutableBoolean> queueInitializer, @NonNull final CrawlDocRecordFactory docRecordFactory, final BiConsumer<Crawler, Boolean> beforeCrawlerExecution, final Consumer<Crawler> afterCrawlerExecution, final BiConsumer<Crawler, CrawlDoc> beforeDocumentProcessing, final BiConsumer<Crawler, CrawlDoc> afterDocumentProcessing, final BiConsumer<Crawler, CrawlDoc> beforeDocumentFinalizing, final BiConsumer<Crawler, CrawlDoc> afterDocumentFinalizing) {
        java.util.Objects.requireNonNull(crawlerImplContext, "crawlerImplContext is marked non-null but is null");
        java.util.Objects.requireNonNull(fetcherProvider, "fetcherProvider is marked non-null but is null");
        java.util.Objects.requireNonNull(crawlDocRecordType, "crawlDocRecordType is marked non-null but is null");
        java.util.Objects.requireNonNull(queuePipeline, "queuePipeline is marked non-null but is null");
        java.util.Objects.requireNonNull(importerPipeline, "importerPipeline is marked non-null but is null");
        java.util.Objects.requireNonNull(committerPipeline, "committerPipeline is marked non-null but is null");
        java.util.Objects.requireNonNull(docRecordFactory, "docRecordFactory is marked non-null but is null");
        this.crawlerImplContext = crawlerImplContext;
        this.fetcherProvider = fetcherProvider;
        this.crawlDocRecordType = crawlDocRecordType;
        this.queuePipeline = queuePipeline;
        this.importerPipeline = importerPipeline;
        this.committerPipeline = committerPipeline;
        this.queueInitializer = queueInitializer;
        this.docRecordFactory = docRecordFactory;
        this.beforeCrawlerExecution = beforeCrawlerExecution;
        this.afterCrawlerExecution = afterCrawlerExecution;
        this.beforeDocumentProcessing = beforeDocumentProcessing;
        this.afterDocumentProcessing = afterDocumentProcessing;
        this.beforeDocumentFinalizing = beforeDocumentFinalizing;
        this.afterDocumentFinalizing = afterDocumentFinalizing;
    }


    @java.lang.SuppressWarnings("all")
    @lombok.Generated
    public static class CrawlerImplBuilder {
        @java.lang.SuppressWarnings("all")
        @lombok.Generated
        private boolean crawlerImplContext$set;
        @java.lang.SuppressWarnings("all")
        @lombok.Generated
        private Supplier<Object> crawlerImplContext$value;
        @java.lang.SuppressWarnings("all")
        @lombok.Generated
        private Function<Crawler, ? extends Fetcher<? extends FetchRequest, ? extends FetchResponse>> fetcherProvider;
        @java.lang.SuppressWarnings("all")
        @lombok.Generated
        private boolean crawlDocRecordType$set;
        @java.lang.SuppressWarnings("all")
        @lombok.Generated
        private Class<? extends CrawlDocRecord> crawlDocRecordType$value;
        @java.lang.SuppressWarnings("all")
        @lombok.Generated
        private QueuePipeline queuePipeline;
        @java.lang.SuppressWarnings("all")
        @lombok.Generated
        private ImporterPipeline importerPipeline;
        @java.lang.SuppressWarnings("all")
        @lombok.Generated
        private CommitterPipeline committerPipeline;
        @java.lang.SuppressWarnings("all")
        @lombok.Generated
        private boolean queueInitializer$set;
        @java.lang.SuppressWarnings("all")
        @lombok.Generated
        private Function<QueueInitContext, MutableBoolean> queueInitializer$value;
        @java.lang.SuppressWarnings("all")
        @lombok.Generated
        private boolean docRecordFactory$set;
        @java.lang.SuppressWarnings("all")
        @lombok.Generated
        private CrawlDocRecordFactory docRecordFactory$value;
        @java.lang.SuppressWarnings("all")
        @lombok.Generated
        private BiConsumer<Crawler, Boolean> beforeCrawlerExecution;
        @java.lang.SuppressWarnings("all")
        @lombok.Generated
        private Consumer<Crawler> afterCrawlerExecution;
        @java.lang.SuppressWarnings("all")
        @lombok.Generated
        private BiConsumer<Crawler, CrawlDoc> beforeDocumentProcessing;
        @java.lang.SuppressWarnings("all")
        @lombok.Generated
        private BiConsumer<Crawler, CrawlDoc> afterDocumentProcessing;
        @java.lang.SuppressWarnings("all")
        @lombok.Generated
        private BiConsumer<Crawler, CrawlDoc> beforeDocumentFinalizing;
        @java.lang.SuppressWarnings("all")
        @lombok.Generated
        private BiConsumer<Crawler, CrawlDoc> afterDocumentFinalizing;

        @java.lang.SuppressWarnings("all")
        @lombok.Generated
        CrawlerImplBuilder() {
        }

        /**
         * Holds objects specific to a given crawler implementation.
         * Useful for keeping objects and state not directly part of
         * Crawler.
         * @return {@code this}.
         */
        @java.lang.SuppressWarnings("all")
        @lombok.Generated
        public CrawlerImpl.CrawlerImplBuilder crawlerImplContext(@NonNull final Supplier<Object> crawlerImplContext) {
            java.util.Objects.requireNonNull(crawlerImplContext, "crawlerImplContext is marked non-null but is null");
            this.crawlerImplContext$value = crawlerImplContext;
            crawlerImplContext$set = true;
            return this;
        }

        /**
         * Provides a required fetcher implementation, responsible for obtaining
         * resources being crawled using one or more different fetcher
         * implementations.
         * @param multiFetcherProvider fetcher provider function
         * @return {@code this}.
         */
        @java.lang.SuppressWarnings("all")
        @lombok.Generated
        public CrawlerImpl.CrawlerImplBuilder fetcherProvider(@NonNull final Function<Crawler, ? extends Fetcher<? extends FetchRequest, ? extends FetchResponse>> fetcherProvider) {
            java.util.Objects.requireNonNull(fetcherProvider, "fetcherProvider is marked non-null but is null");
            this.fetcherProvider = fetcherProvider;
            return this;
        }

        /**
         * The exact type of {@link CrawlDocRecord} if your crawler is subclassing
         * it. Defaults to {@link CrawlDocRecord} class.
         * @param crawlDocRecordType crawl document record class
         * @return {@code this}.
         */
        @java.lang.SuppressWarnings("all")
        @lombok.Generated
        public CrawlerImpl.CrawlerImplBuilder crawlDocRecordType(@NonNull final Class<? extends CrawlDocRecord> crawlDocRecordType) {
            java.util.Objects.requireNonNull(crawlDocRecordType, "crawlDocRecordType is marked non-null but is null");
            this.crawlDocRecordType$value = crawlDocRecordType;
            crawlDocRecordType$set = true;
            return this;
        }

        /**
         * Required pipeline to be executed for each reference that should
         * end-up in the crawler queue.
         * @param queuePipeline queue pipeline
         * @return {@code this}.
         */
        @java.lang.SuppressWarnings("all")
        @lombok.Generated
        public CrawlerImpl.CrawlerImplBuilder queuePipeline(@NonNull final QueuePipeline queuePipeline) {
            java.util.Objects.requireNonNull(queuePipeline, "queuePipeline is marked non-null but is null");
            this.queuePipeline = queuePipeline;
            return this;
        }

        /**
         * Required pipeline to be executed for each reference read
         * from the crawler queue up to the importing of the corresponding
         * document.
         * @param importerPipeline importer pipeline
         * @return {@code this}.
         */
        @java.lang.SuppressWarnings("all")
        @lombok.Generated
        public CrawlerImpl.CrawlerImplBuilder importerPipeline(@NonNull final ImporterPipeline importerPipeline) {
            java.util.Objects.requireNonNull(importerPipeline, "importerPipeline is marked non-null but is null");
            this.importerPipeline = importerPipeline;
            return this;
        }

        /**
         * Required pipeline to be executed for each document that has been
         * imported and are ready to be committed for insertion/update or
         * deletion.
         * @param committerPipeline committer pipeline
         * @return {@code this}.
         */
        @java.lang.SuppressWarnings("all")
        @lombok.Generated
        public CrawlerImpl.CrawlerImplBuilder committerPipeline(@NonNull final CommitterPipeline committerPipeline) {
            java.util.Objects.requireNonNull(committerPipeline, "committerPipeline is marked non-null but is null");
            this.committerPipeline = committerPipeline;
            return this;
        }

        /**
         * Function responsible for initializing a queue, which typically involved
         * inserting the initial references necessary to start crawling.
         * The function's return value indicate if we are done initializing
         * the queue.  Should always be <code>true</code> unless
         * the queue can be initialized asynchronously. In such case,
         * the mutable boolean can be returned right away, but must be set to
         * <code>true</code> when initialization is complete.
         * Defaults to {@link CoreQueueInitializer}.
         * @param queueInitializer queue initializer function
         * @return {@code this}.
         */
        @java.lang.SuppressWarnings("all")
        @lombok.Generated
        public CrawlerImpl.CrawlerImplBuilder queueInitializer(final Function<QueueInitContext, MutableBoolean> queueInitializer) {
            this.queueInitializer$value = queueInitializer;
            queueInitializer$set = true;
            return this;
        }

        /**
         * Function responsible for creating new document records
         * specific to this crawler implementation. The default factory
         * creates instances of {@link CrawlDocRecord} initialized with
         * a possible parent document record.
         * @param docRecordFactory factory function for creating doc records
         * @return {@code this}.
         */
        @java.lang.SuppressWarnings("all")
        @lombok.Generated
        public CrawlerImpl.CrawlerImplBuilder docRecordFactory(@NonNull final CrawlDocRecordFactory docRecordFactory) {
            java.util.Objects.requireNonNull(docRecordFactory, "docRecordFactory is marked non-null but is null");
            this.docRecordFactory$value = docRecordFactory;
            docRecordFactory$set = true;
            return this;
        }

        /**
         * Gives crawler implementations a chance to prepare before execution
         * starts. Invoked right after the
         * {@link CrawlerEvent#CRAWLER_RUN_BEGIN} event is fired.
         * This method is different than the {@link #initCrawler()} method,
         * which is invoked for any type of actions where as this one is only
         * invoked before an effective request for crawling.
         * @param beforeCrawlerExecution bi-consumer accepting a crawler and
         *     a "resume" indicator.
         * @return {@code this}.
         */
        @java.lang.SuppressWarnings("all")
        @lombok.Generated
        public CrawlerImpl.CrawlerImplBuilder beforeCrawlerExecution(final BiConsumer<Crawler, Boolean> beforeCrawlerExecution) {
            this.beforeCrawlerExecution = beforeCrawlerExecution;
            return this;
        }

        /**
         * Gives crawler implementations a chance to do something right after
         * the crawler is done processing its last reference, before all resources
         * are shut down.
         * Invoked right after {@link CrawlerEvent#CRAWLER_STOP_END} or
         * {@link CrawlerEvent#CRAWLER_RUN_END} (depending which of the two is
         * triggered).
         * @param afterCrawlerExecution consumer accepting a crawler
         * @return {@code this}.
         */
        @java.lang.SuppressWarnings("all")
        @lombok.Generated
        public CrawlerImpl.CrawlerImplBuilder afterCrawlerExecution(final Consumer<Crawler> afterCrawlerExecution) {
            this.afterCrawlerExecution = afterCrawlerExecution;
            return this;
        }

        /**
         * @return {@code this}.
         */
        @java.lang.SuppressWarnings("all")
        @lombok.Generated
        public CrawlerImpl.CrawlerImplBuilder beforeDocumentProcessing(final BiConsumer<Crawler, CrawlDoc> beforeDocumentProcessing) {
            this.beforeDocumentProcessing = beforeDocumentProcessing;
            return this;
        }

        /**
         * @return {@code this}.
         */
        @java.lang.SuppressWarnings("all")
        @lombok.Generated
        public CrawlerImpl.CrawlerImplBuilder afterDocumentProcessing(final BiConsumer<Crawler, CrawlDoc> afterDocumentProcessing) {
            this.afterDocumentProcessing = afterDocumentProcessing;
            return this;
        }

        /**
         * @return {@code this}.
         */
        @java.lang.SuppressWarnings("all")
        @lombok.Generated
        public CrawlerImpl.CrawlerImplBuilder beforeDocumentFinalizing(final BiConsumer<Crawler, CrawlDoc> beforeDocumentFinalizing) {
            this.beforeDocumentFinalizing = beforeDocumentFinalizing;
            return this;
        }

        /**
         * @return {@code this}.
         */
        @java.lang.SuppressWarnings("all")
        @lombok.Generated
        public CrawlerImpl.CrawlerImplBuilder afterDocumentFinalizing(final BiConsumer<Crawler, CrawlDoc> afterDocumentFinalizing) {
            this.afterDocumentFinalizing = afterDocumentFinalizing;
            return this;
        }

        @java.lang.SuppressWarnings("all")
        @lombok.Generated
        public CrawlerImpl build() {
            Supplier<Object> crawlerImplContext$value = this.crawlerImplContext$value;
            if (!this.crawlerImplContext$set) crawlerImplContext$value = CrawlerImpl.$default$crawlerImplContext();
            Class<? extends CrawlDocRecord> crawlDocRecordType$value = this.crawlDocRecordType$value;
            if (!this.crawlDocRecordType$set) crawlDocRecordType$value = CrawlerImpl.$default$crawlDocRecordType();
            Function<QueueInitContext, MutableBoolean> queueInitializer$value = this.queueInitializer$value;
            if (!this.queueInitializer$set) queueInitializer$value = CrawlerImpl.$default$queueInitializer();
            CrawlDocRecordFactory docRecordFactory$value = this.docRecordFactory$value;
            if (!this.docRecordFactory$set) docRecordFactory$value = CrawlerImpl.$default$docRecordFactory();
            return new CrawlerImpl(crawlerImplContext$value, this.fetcherProvider, crawlDocRecordType$value, this.queuePipeline, this.importerPipeline, this.committerPipeline, queueInitializer$value, docRecordFactory$value, this.beforeCrawlerExecution, this.afterCrawlerExecution, this.beforeDocumentProcessing, this.afterDocumentProcessing, this.beforeDocumentFinalizing, this.afterDocumentFinalizing);
        }

        @java.lang.Override
        @java.lang.SuppressWarnings("all")
        @lombok.Generated
        public java.lang.String toString() {
            return "CrawlerImpl.CrawlerImplBuilder(crawlerImplContext$value=" + this.crawlerImplContext$value + ", fetcherProvider=" + this.fetcherProvider + ", crawlDocRecordType$value=" + this.crawlDocRecordType$value + ", queuePipeline=" + this.queuePipeline + ", importerPipeline=" + this.importerPipeline + ", committerPipeline=" + this.committerPipeline + ", queueInitializer$value=" + this.queueInitializer$value + ", docRecordFactory$value=" + this.docRecordFactory$value + ", beforeCrawlerExecution=" + this.beforeCrawlerExecution + ", afterCrawlerExecution=" + this.afterCrawlerExecution + ", beforeDocumentProcessing=" + this.beforeDocumentProcessing + ", afterDocumentProcessing=" + this.afterDocumentProcessing + ", beforeDocumentFinalizing=" + this.beforeDocumentFinalizing + ", afterDocumentFinalizing=" + this.afterDocumentFinalizing + ")";
        }
    }

    @java.lang.SuppressWarnings("all")
    @lombok.Generated
    public static CrawlerImpl.CrawlerImplBuilder builder() {
        return new CrawlerImpl.CrawlerImplBuilder();
    }

    /**
     * Holds objects specific to a given crawler implementation.
     * Useful for keeping objects and state not directly part of
     * Crawler.
     */
    @NonNull
    @java.lang.SuppressWarnings("all")
    @lombok.Generated
    public Supplier<Object> crawlerImplContext() {
        return this.crawlerImplContext;
    }

    /**
     * Provides a required fetcher implementation, responsible for obtaining
     * resources being crawled using one or more different fetcher
     * implementations.
     * @return a function returning a fetcher to associate with a given crawler.
     */
    @NonNull
    @java.lang.SuppressWarnings("all")
    @lombok.Generated
    public Function<Crawler, ? extends Fetcher<? extends FetchRequest, ? extends FetchResponse>> fetcherProvider() {
        return this.fetcherProvider;
    }

    /**
     * The exact type of {@link CrawlDocRecord} if your crawler is subclassing
     * it. Defaults to {@link CrawlDocRecord} class.
     * @return crawl document record class
     */
    @NonNull
    @java.lang.SuppressWarnings("all")
    @lombok.Generated
    public Class<? extends CrawlDocRecord> crawlDocRecordType() {
        return this.crawlDocRecordType;
    }

    /**
     * Required pipeline to be executed for each reference that should
     * end-up in the crawler queue.
     * @return queue pipeline
     */
    @NonNull
    @java.lang.SuppressWarnings("all")
    @lombok.Generated
    public QueuePipeline queuePipeline() {
        return this.queuePipeline;
    }

    /**
     * Required pipeline to be executed for each reference read
     * from the crawler queue up to the importing of the corresponding
     * document.
     * @return importer pipeline
     */
    @NonNull
    @java.lang.SuppressWarnings("all")
    @lombok.Generated
    public ImporterPipeline importerPipeline() {
        return this.importerPipeline;
    }

    /**
     * Required pipeline to be executed for each document that has been
     * imported and are ready to be committed for insertion/update or
     * deletion.
     * @return committer pipeline
     */
    @NonNull
    @java.lang.SuppressWarnings("all")
    @lombok.Generated
    public CommitterPipeline committerPipeline() {
        return this.committerPipeline;
    }

    /**
     * Function responsible for initializing a queue, which typically involved
     * inserting the initial references necessary to start crawling.
     * The function's return value indicate if we are done initializing
     * the queue.  Should always be <code>true</code> unless
     * the queue can be initialized asynchronously. In such case,
     * the mutable boolean can be returned right away, but must be set to
     * <code>true</code> when initialization is complete.
     * Defaults to {@link CoreQueueInitializer}.
     * @return queue initializer function
     */
    @java.lang.SuppressWarnings("all")
    @lombok.Generated
    public Function<QueueInitContext, MutableBoolean> queueInitializer() {
        return this.queueInitializer;
    }

    /**
     * Function responsible for creating new document records
     * specific to this crawler implementation. The default factory
     * creates instances of {@link CrawlDocRecord} initialized with
     * a possible parent document record.
     * @return factory function for creating doc records
     */
    @NonNull
    @java.lang.SuppressWarnings("all")
    @lombok.Generated
    public CrawlDocRecordFactory docRecordFactory() {
        return this.docRecordFactory;
    }

    /**
     * Gives crawler implementations a chance to prepare before execution
     * starts. Invoked right after the
     * {@link CrawlerEvent#CRAWLER_RUN_BEGIN} event is fired.
     * This method is different than the {@link #initCrawler()} method,
     * which is invoked for any type of actions where as this one is only
     * invoked before an effective request for crawling.
     * @return bi-consumer accepting a crawler and a "resume" indicator
     */
    @java.lang.SuppressWarnings("all")
    @lombok.Generated
    public BiConsumer<Crawler, Boolean> beforeCrawlerExecution() {
        return this.beforeCrawlerExecution;
    }

    /**
     * Gives crawler implementations a chance to do something right after
     * the crawler is done processing its last reference, before all resources
     * are shut down.
     * Invoked right after {@link CrawlerEvent#CRAWLER_STOP_END} or
     * {@link CrawlerEvent#CRAWLER_RUN_END} (depending which of the two is
     * triggered).
     * @return consumer accepting a crawler
     */
    @java.lang.SuppressWarnings("all")
    @lombok.Generated
    public Consumer<Crawler> afterCrawlerExecution() {
        return this.afterCrawlerExecution;
    }

    @java.lang.SuppressWarnings("all")
    @lombok.Generated
    public BiConsumer<Crawler, CrawlDoc> beforeDocumentProcessing() {
        return this.beforeDocumentProcessing;
    }

    @java.lang.SuppressWarnings("all")
    @lombok.Generated
    public BiConsumer<Crawler, CrawlDoc> afterDocumentProcessing() {
        return this.afterDocumentProcessing;
    }

    @java.lang.SuppressWarnings("all")
    @lombok.Generated
    public BiConsumer<Crawler, CrawlDoc> beforeDocumentFinalizing() {
        return this.beforeDocumentFinalizing;
    }

    @java.lang.SuppressWarnings("all")
    @lombok.Generated
    public BiConsumer<Crawler, CrawlDoc> afterDocumentFinalizing() {
        return this.afterDocumentFinalizing;
    }
//        protected abstract void markReferenceVariationsAsProcessed(
//                CrawlDocRecord crawlRef);
//
//
//        protected abstract CrawlDocRecord createChildDocInfo(
//                String embeddedReference, CrawlDocRecord parentCrawlRef);
//
//        protected abstract ImporterResponse executeImporterPipeline(
//                ImporterPipelineContext context);
//        //TODO, replace with DocumentPipelineContext?
//        protected abstract void executeCommitterPipeline(
//                Crawler crawler, CrawlDoc doc);
//        private Builder() {}
//
//        public Crawler build(@NonNull Collector collector) {
//            //TODO validate mandatories are there (or validate in crawler constructor
//
//            return new Crawler(collector, this);
//        }
}
