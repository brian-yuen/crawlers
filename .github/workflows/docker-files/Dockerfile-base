FROM ubuntu:22.04 AS base
ARG crawler_type
ARG build_version
ARG dl_filename

ENV COLLECTOR_HOME=/nxer/collector \
	WORKDIR=/nxer/outputs/workdir \
    COLLECTOR_LOG_DIR=/nxer/collector/logs \
	NORCONEX_HOME=/nxer \
	COLLECTOR_CONFIG_FILE=crawler-config.xml \	
    PATH="/nxer/collector:/nxer/docker-scripts:$PATH"

WORKDIR $NORCONEX_HOME

COPY .github/workflows/support-files .

RUN apt-get -y update ; \
    apt-get install -y nano ; \
    apt-get install -y curl ; \
    apt-get install -y unzip ; \
    apt-get install -y iputils-ping ; \
    apt install bash-completion ; \
    curl -LO https://download.oracle.com/java/17/latest/jdk-17_linux-x64_bin.deb ; \
    dpkg -i jdk-17_linux-x64_bin.deb ; \    
    rm *.deb;

FROM base AS regular
WORKDIR $NORCONEX_HOME

COPY downloaded/$crawler_type/*.zip .
RUN set -e; \ 
    unzip ${dl_filename}; \
    mkdir collector; \
    mv nx-crawler-${crawler_type}-${build_version} ${COLLECTOR_HOME}; \
    mv log4j-core-2.23.1.jar1 "${COLLECTOR_HOME}/lib/log4j-core-2.23.1.jar"; \
    mv log4j-slf4j2-impl-2.23.1.jar1 "${COLLECTOR_HOME}/lib/log4j-slf4j2-impl-2.23.1.jar"; \    
    chmod +x ${COLLECTOR_HOME}/crawl-${crawler_type}.*; \
    rm *.zip

# Entry point when running docker container
ENTRYPOINT ["crawl-web.sh"]

# Crawl-web options
CMD ["start", "-config=/nxer/collector/configs/crawler-config.xml"]

FROM base AS snapshot
WORKDIR $NORCONEX_HOME

COPY downloaded/$crawler_type/*.zip .
RUN set -e; \ 
    unzip ${dl_filename}; \
    mkdir collector; \
    mv nx-crawler-${crawler_type}-${build_version}-SNAPSHOT/* ${COLLECTOR_HOME}; \
    mv log4j-core-2.23.1.jar1 "${COLLECTOR_HOME}/lib/log4j-core-2.23.1.jar"; \
    mv log4j-slf4j2-impl-2.23.1.jar1 "${COLLECTOR_HOME}/lib/log4j-slf4j2-impl-2.23.1.jar"; \    
    chmod +x ${COLLECTOR_HOME}/crawl-${crawler_type}.*; \
    rm *.zip;     

# Entry point when running docker container
ENTRYPOINT ["crawl-web.sh"]

# Crawl-web options
CMD ["start", "-config=/nxer/collector/configs/crawler-config.xml"]
